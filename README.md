# ğŸ™ï¸ Speech-to-Speech RAG System for CIH Bank FAQ

Voice-based question answering system using Retrieval-Augmented Generation (RAG) with French language support.

## ğŸ“Š System Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SPEECH-TO-SPEECH RAG PIPELINE                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. ğŸ¤ AUDIO INPUT
   â””â”€> User speaks question (5 seconds) // you can add more seconds 
       â””â”€> sounddevice captures microphone input
           â””â”€> Saves as WAV (16kHz, mono)

2. ğŸ”¤ SPEECH-TO-TEXT (STT)
   â””â”€> faster-whisper processes audio
       â”œâ”€> Model: small (244M parameters)
       â”œâ”€> Language: French
       â”œâ”€> Device: CPU with int8 quantization
       â””â”€> Output: "Comment ouvrir un compte?"

3. ğŸ§  EMBEDDING GENERATION
   â””â”€> Ollama embeddinggemma:latest
       â”œâ”€> Input: Question text
       â”œâ”€> Output: 768-dimensional vector
       â””â”€> Running on: localhost:11434

4. ğŸ” VECTOR SEARCH
   â””â”€> Qdrant semantic search
       â”œâ”€> Collection: "faq"
       â”œâ”€> Metric: Cosine similarity
       â”œâ”€> Returns: Top 4 relevant chunks
       â””â”€> Running on: localhost:6333

5. ğŸ’¬ LLM GENERATION
   â””â”€> OpenAI GPT-4o-mini via OpenRouter
       â”œâ”€> Input: Context chunks + question
       â”œâ”€> Streaming: Yes (real-time text)
       â””â”€> Output: French answer

6. ğŸ”Š TEXT-TO-SPEECH (TTS)
   â””â”€> Coqui TTS VITS model
       â”œâ”€> Model: tts_models/fr/css10/vits
       â”œâ”€> Language: French
       â”œâ”€> Sample rate: 22050 Hz
       â””â”€> Output: WAV audio

7. ğŸµ AUDIO PLAYBACK
   â””â”€> sounddevice plays response
       â””â”€> User hears the answer
```

## ğŸ—ï¸ Project Structure

```
speesh-to-speesh/
â”œâ”€â”€ rag.py                 # Main speech-to-speech pipeline
â”œâ”€â”€ setup_vectors.py       # Vector database initialization
â”œâ”€â”€ text_pdf.txt          # CIH Bank FAQ source document
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md             # This file

```

## ğŸ”§ Technologies Used

### Speech-to-Text
- **[faster-whisper](https://github.com/SYSTRAN/faster-whisper)** - Optimized OpenAI Whisper implementation
  - CTranslate2 backend for faster inference
  - Model: `small` (244M params)
  - Quantization: `int8` for CPU efficiency
  - Language: French (`fr`)
  - Beam size: 1 (fastest decoding)

### Embeddings
- **[Ollama](https://ollama.ai)** - Local LLM server
  - Model: `embeddinggemma:latest`
  - Dimensions: 768
  - Purpose: Convert text to semantic vectors

### Vector Database
- **[Qdrant](https://qdrant.tech)** - Vector similarity search
  - Distance metric: Cosine similarity
  - Collection: `faq` (CIH Bank FAQ chunks)
  - Chunk size: ~400 characters with overlap

### Language Model
- **OpenRouter API** - LLM gateway // or local llm
  - Model: `openai/gpt-4o-mini`
  - Streaming: Enabled
  - Purpose: Generate contextual answers

### Text-to-Speech
- **[Coqui TTS](https://github.com/coqui-ai/TTS)** - Neural TTS
  - Model: `tts_models/fr/css10/vits`
  - Quality: Clean French voice
  - Sample rate: 22050 Hz

### Audio I/O
- **sounddevice** - Cross-platform audio recording/playback

## ğŸ’» CPU vs GPU Configuration

### Current Setup: CPU âœ…
```python
whisper_model = WhisperModel("small", device="cpu", compute_type="int8")
```

**Pros:**
- âœ… Works on any machine (no GPU required)
- âœ… Lower memory usage (~1GB RAM)
- âœ… Good for development and testing
- âœ… Sufficient for single-user scenarios

**Cons:**
- âš ï¸ Slower transcription (~2-3 seconds per request)
- âš ï¸ Limited to smaller models (tiny, base, small)

**When to use CPU:**
- Development and testing
- Single-user or low-traffic deployments
- No NVIDIA GPU available
- Budget constraints

---

### GPU Configuration (Optional) ğŸš€
```python
whisper_model = WhisperModel("small", device="cuda", compute_type="float16")
# Or for best quality:
whisper_model = WhisperModel("large-v3", device="cuda", compute_type="float16")
```

**Pros:**
- âœ… Much faster transcription (~0.2-0.5 seconds)
- âœ… Can use larger models (medium, large-v3)
- âœ… Better accuracy with large models
- âœ… Handles concurrent requests

**Cons:**
- âš ï¸ Requires NVIDIA GPU with CUDA
- âš ï¸ Higher memory usage (4-8GB VRAM)
- âš ï¸ Additional setup (CUDA, cuDNN)

**When to use GPU:**
- Production deployments
- High-traffic scenarios
- Need for faster response times
- Have NVIDIA GPU with 4GB+ VRAM
- Want to use large/medium models

**GPU Requirements:**
- NVIDIA GPU with CUDA support
- Minimum 4GB VRAM (for small/medium)
- 8GB+ VRAM recommended (for large models)
- CUDA 11.8+ and cuDNN installed

## ğŸš€ Installation & Setup

### 1. Clone Repository

### 2. Install Python Dependencies
```bash
pip install -r requirements.txt
```

### 3. Start Qdrant
```bash
# Using Docker (recommended)
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant

```

### 4. Start Ollama & Pull Embedding Model
```bash
# Install Ollama from https://ollama.ai
# Then pull the embedding model:
ollama pull embeddinggemma:latest
```

### 5. Initialize Vector Database (First Time Only)
```bash
python setup_vectors.py
```

This will:
- Read `text_pdf.txt`
- Split into chunks (~400 chars each)
- Generate embeddings for each chunk
- Store in Qdrant collection

### 6. Run the Application
```bash
python rag.py
```

## ğŸ“– Usage

1. Run `python rag.py`
2. Wait for "ğŸ™ï¸ Parlez maintenant (5s)..."
3. Speak your question in French
4. System will:
   - Transcribe your question
   - Search relevant FAQ chunks
   - Generate streaming answer (appears word-by-word)
   - Speak the answer back to you

**Example:**
```
ğŸ™ï¸ Parlez maintenant (5s)...
ğŸ¤ Transcription...
Vous: Comment ouvrir un compte?

ğŸ”Š Assistant: Pour ouvrir un compte Ã  CIH Bank, vous devez vous
rendre dans une agence CIH Bank et souscrire...
ğŸµ Lecture audio...
âœ… Done!
```

## âš™ï¸ Configuration

Edit `rag.py` to customize:

```python
# Recording duration
RECORD_SECONDS = 5  # Change to 3, 7, 10 seconds

# Whisper model size
whisper_model = WhisperModel("small", ...)  # tiny, base, medium, large

# Number of retrieved chunks
chunks = search_chunks(question, top_k=4)  # 2, 3, 5, etc.

# TTS speed (in speak function)
wav = tts.tts(text=text, speed=1.0)  # 0.8 (slower), 1.2 (faster)
```

## ğŸ¯ Whisper Model Comparison

| Model | Parameters | Speed | Accuracy | VRAM (GPU) | Use Case |
|-------|-----------|-------|----------|------------|----------|
| `tiny` | 39M | âš¡âš¡âš¡ Very Fast | â­ Basic | ~1GB | Quick testing |
| `base` | 74M | âš¡âš¡ Fast | â­â­ Good | ~1GB | Development |
| **`small`** | **244M** | **âš¡ Fast** | **â­â­â­ Good** | **~2GB** | **Recommended (CPU)** |
| `medium` | 769M | ğŸ¢ Medium | â­â­â­â­ Very Good | ~5GB | GPU recommended |
| `large-v3` | 1.55B | ğŸ¢ğŸ¢ Slow | â­â­â­â­â­ Excellent | ~10GB | GPU required |



## ğŸ“¦ Dependencies

```
requests           # HTTP client for APIs
qdrant-client      # Vector database client
numpy              # Numerical operations
faster-whisper     # Optimized Whisper STT
TTS                # Coqui text-to-speech
sounddevice        # Audio I/O
```

## ğŸ”„ Update Workflow

To update the FAQ knowledge base:

1. Edit `text_pdf.txt` with new content
2. Run `python setup_vectors.py` to rebuild vectors
3. Run `python rag.py` to test

